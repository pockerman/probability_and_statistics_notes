{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "359e01e4-7cd7-439f-b22b-23db2d5f5f6a",
   "metadata": {},
   "source": [
    "# Evaluating Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313489d6-72c2-40ea-b6ef-28b9a6d7b0c9",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d012413-8f05-4ba7-b081-e1d6962f982d",
   "metadata": {},
   "source": [
    "We have so far seen a number of classification techniques. For a given problem, more than \n",
    "one algorithm may be applicable. There is therefore a need to examine how we can \n",
    "assess how good a selected algorithm is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e049b06-b1ed-4765-8bd7-477524464b66",
   "metadata": {},
   "source": [
    "In this section we will review methods that we can employ to evaluate the\n",
    "suitability of a classifier. Whatever the conclusion we draw from the analysis one should \n",
    "not bear in mind that this is conditioned on the dataset given. Thus, we assess\n",
    "the performance of an algorithm on the specified application and say nothing about the\n",
    "performance of the algorithm in general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2065c49b-03b1-41ce-b309-aaa391891ab3",
   "metadata": {},
   "source": [
    "Finally, note that for any learning algorithm there will be a dataset where the algorithm\n",
    "will be very accurate and another dataset where the algorithm will perform poorly. \n",
    "This is called the No Free Lunch Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48869528-0403-488a-82f8-c39179196bdf",
   "metadata": {},
   "source": [
    "## Evaluating classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a736b8-8245-4ec3-9c3e-1bd972ec0a04",
   "metadata": {},
   "source": [
    "As we already know, a model typically is trained on a training set and evaluated over \n",
    "a test set. Typically, we do not want the model to be trained over the test set as this\n",
    "will be a form of cheating.  In addition, we have seen that accuracy is a common metric that can be used\n",
    "in order to evaluate the performance of a classifier. Accuracy is defined as\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "Accuracy=\\frac{\\text{Total number of correct classifications}}{\\text{Total number of points}}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde65e4-087c-451b-abcf-de89118d3f11",
   "metadata": {},
   "source": [
    "If we know the accuracy, we can compute the error rate and vice versa as the two are related according to\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Error rate} = 1 - \\text{Accuracy} \\tag{1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad1c08b-c300-47f0-aaea-ce7480d2e459",
   "metadata": {},
   "source": [
    "Conceptually, we can view accuracy as an estimate of the probability that an arbitrary \n",
    "instance $\\mathbf{x}\\in \\mathbf{X}$ is classified correctly i.e. as the probability [1]\n",
    "\n",
    "\\begin{equation}\n",
    "P(\\hat{c}(\\mathbf{x})) = c(\\mathbf{x}| \\hat{f})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec7a692-365c-4c9c-bb20-f3dde8712168",
   "metadata": {},
   "source": [
    "However, when we deal with imbalanced classes this metric is not enough and can even be misleading. A <a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\">confusion matrix</a> allows us to visualize  \n",
    "various quality metrics associated with the goodness of fit. Some of these metrics are described below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7f65f-7c90-45fa-905e-c3eb38db0c3a",
   "metadata": {},
   "source": [
    "### Precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6a3659-27fa-4b9a-a250-0ce6ceba12e9",
   "metadata": {},
   "source": [
    "Precision and recall are two error measures used to assess the quality\n",
    "of the results produced by a binary classifier. They are defined as follows\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d4bf06-ac0c-49f4-9bd4-8f0c9da7700a",
   "metadata": {},
   "source": [
    "Notice that the recall is also known as sensitivity of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f615968-ba34-46d9-8c60-4a9910a9246b",
   "metadata": {},
   "source": [
    "### F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10729c3b-29aa-4644-864e-350783cb9697",
   "metadata": {},
   "source": [
    "The f-measure equals the harmonic mean of a classifierâ€™s precision and recall. Namely,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a607c-0fee-485d-a848-fca828af1493",
   "metadata": {},
   "source": [
    "### Receiver operating characteristic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f966be-2047-4aed-b9af-7f0e12357351",
   "metadata": {},
   "source": [
    "## Statistical distribution of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4cbec-03d1-4435-877a-3a335e8b8f8e",
   "metadata": {},
   "source": [
    "Machine learning alrgorithms are in general probabilistic in nature. \n",
    "Thus we need to account somehow for the randomness in the training data and/or\n",
    "the weights initialization e.t.c. To do so, we use the same algorithm and generate\n",
    "multiple classifiers and test them on multiple test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c02b29-f6ef-45eb-adea-9f5f141ab144",
   "metadata": {},
   "source": [
    "Bootstraping may be a procedure we can use to create randomly selected training and\n",
    "test datasets. This approach will create one or more training datasets. Given that boostrap is\n",
    "essentially sampling with replacement, some of training sets are repeated. The corresponding test datasets are then constructed from the set of examples that were not selected for the respective training datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60669163-1fa7-4f9a-99bf-ac855e98ba35",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89169e1-dde2-43fa-a7ef-87d0ed5428d9",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8324f2-1ab6-4fbf-ba4d-0c7cb436b6ba",
   "metadata": {},
   "source": [
    "1. Peter Flach, _Machine Learning The Art and Science of Algorithms that Make Sense of Data_, Cambridge Press"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
