{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d4f050-a036-4027-8b11-767fc5b335d1",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning-Regression\n",
    "\n",
    "Learning aims to create an internal model or an abstraction of the external world. More comprehensively, Dehaene introduced in [1] seven key definitions of learning that lie at the heart of present-day machine learning algorithms. These definitions include learning is adjusting the parameters of a mental model, learning is exploring a combinatorial explosion, learning is minimizing errors, learning is exploring the space of possibilities, learning is optimizing a reward function, learning is restricting search space, and learning is projecting a priori hypotheses. Machine learning (ML) is a subfield of AI that endows an artificial system/process with the ability to learn from experience and from observation without being explicitly programmed. Mitchell in [2] defines ML as follows: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.” In his book The Master Algorithm [3], Pedro Domingos summarizes the machine learning schools of thoughts into five main schools as illustrated in Figure 11.1.\n",
    "\n",
    "- Bayesians with probabilistic inference as the master algorithm.\n",
    "- Symbolists with rules and trees as the main core algorithm within this paradigm.\n",
    "- Connectionists who use neural networks with backpropagation as a master algorithm.\n",
    "- Revolutionaries who rely on the evolution computing paradigm.\n",
    "- Analogizers who use mathematical techniques like support vector machines with different kernels.\n",
    "\n",
    "Generally speaking, machine learning algorithms can be categorized into supervised, unsupervised, hybrid learning and reinforcement learning algorithms as illustrated in Figure 11.2.\n",
    "\n",
    "\n",
    "**Supervised learning:** uses inductive inference to approximate mapping functions between data and known labels/classes. This mapping is learned using already labeled training data. Classification (predicting discrete or categorical values) and regression (predicting continuous values) are common tasks in supervised learning. For example, classification seeks a scoring function f:Χ×C⟶R, where Χ represents training data space, C represents label/class space. This mapping can be learned using N training examples of the form {(x11, x21, …, xk1, c1), (x12, x22, …, xk2, c2), …, (x1N, x2N, …, xkN, cN )}, where xi is the feature vector of the i-th example, k is number of features and ci is the corresponding class. The predicted class is the class that gives the highest score of f, i.e., c(x)=argmaxcf(x,c). In the context of self-driving cars, supervised learning might be used to train a model to recognize traffic signs. The input data would be images of various traffic signs, and the correct output (the labels) would be the type of each sign. The trained model could then identify traffic signs correctly when driving. Feedforward Neural Networks (FNNs)/Multilayer Perceptrons (MLPs), Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) Networks and Sequence-to-sequence models (Seq2Seq) are examples of common neural network architectures that are typically trained using supervised learning. Example of solving combinatorial problems using supervised machine learning are provided in sections 11.6, 11.7 and 11.9.\n",
    "\n",
    "**Unsupervised learning:** deals with unlabeled data through techniques like clustering and dimensionality reduction. In clustering, for example, n objects (each could be a vector of d features) are given, and the task is to group them based on certain similarity measures into c groups (clusters) in such a way that all objects in a single group have a “natural” relation to one another and objects not in the same group are somehow different. For instance, unsupervised learning might be used in self-driving cars to cluster similar driving scenarios or environments. For example, using unsupervised learning, the car might learn to identify different types of intersections or roundabouts, even if no one has explicitly labeled the data with these categories. Autoencoders, K-means, Density-based spatial clustering (DBSCAN), Principal Component Analysis (PCA) and Self-Organizing Maps (SOMs) are examples of unsupervised learning methods. SOM is explained in subsection 11.4. An example of a combinatorial problem using SOM is provided in section 11.8.\n",
    "\n",
    "\n",
    "**Hybrid Learning:** such as semi-supervised learning, self-supervised learning and multi-instance learning techniques. Semi-supervised learning is a mix of supervised and unsupervised learning, where only a fraction of the input data is labeled with corresponding outputs. In this case, the training process use a small amount of labeled data available and pseudo-label the rest of the dataset. Self-supervised learning is a machine learning process where the model trains itself to learn one part of the input from another part of the input. It is also known as predictive or pretext learning. In self-supervised learning, the unsupervised learning problem is framed as a supervised learning problem by auto-generating the labels. Multiple Instance Learning (MIL) is a type of weakly supervised learning algorithm where training data is arranged in sets called bags, and each bag contains a set of instances. There is only one single label per bag, meaning the individual instances within a bag do not have specific labels. MIL allows leveraging weakly labeled data, which is present in many real-world scenarios where labeling data at the instance level can be costly or impractical.\n",
    "\n",
    "\n",
    "**Reinforcement learning (RL):** learns from interactions through a feedback loop or by trial and error. A learning agent learns to make decisions by taking actions in an environment to maximize some notion of cumulative reward. For self-driving cars, reinforcement learning could be used in the decision-making process. For instance, the car might learn over time the best way to merge into traffic on a busy highway. It would receive positive rewards for successful merges and negative rewards for dangerous maneuvers or failed attempts. Over time, through trial-and-error and the desire to maximize the reward, the car would learn an optimal policy for merging into traffic. More details about RL are provided in the next chapter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358ca7e-8073-4822-8be2-d86f4d1e6261",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Larry Wasserman, _All of Statistics. A Concise Course in Statistical Inference_, Springer 2003."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
