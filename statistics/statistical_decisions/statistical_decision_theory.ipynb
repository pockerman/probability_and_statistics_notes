{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b9ef477-aa4e-42d9-8b83-9a9a05d38247",
   "metadata": {},
   "source": [
    "# Statistical Decision Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39db02f6-2544-49e8-a30d-3848ee411683",
   "metadata": {},
   "source": [
    "Up to now we have seen various methodologies to obtain point estimators of quantities of interest.\n",
    "For example, we have seen maximum likelihood estimation and the method of moments. The question\n",
    "that arises is how do we choose the best estimator? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3f1a1a-dd0b-4600-82e2-90bc446e0e53",
   "metadata": {},
   "source": [
    "<a href=\"https://en.wikipedia.org/wiki/Decision_theory\">Decision theory</a> is a framework we can use in\n",
    "order to compare estimators [1]. In this chapter, we look into decision theory and how we can use it \n",
    "in order to make decisions for estimators. On that note, in this chapter we will use $\\theta$ to denote a\n",
    "paramter of interest and $\\hat{\\theta}$ to denote an estimator of it. In general, $\\theta \\in \\Theta$ where $\\Theta$\n",
    "is a parameter space [1]. Note that in general $\\hat{\\theta}$ depends on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433542a5-a2cb-4351-b958-cf859b5bb57f",
   "metadata": {},
   "source": [
    "In orde to make any decisions on estimators, we need to be able to quantify the discrepancy\n",
    "between $\\theta$ and $\\hat{\\theta}$. The are various ways to do this; below are some examples of\n",
    "loss functions [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc32bd-4790-4f3d-9966-3d5c412e633e",
   "metadata": {},
   "source": [
    "$$L(\\theta, \\hat{\\theta})=(\\theta - \\hat{\\theta})^2$$\n",
    "$$L(\\theta, \\hat{\\theta})=|\\theta - \\hat{\\theta}|$$\n",
    "$$L(\\theta, \\hat{\\theta})=\\int log\\left(\\frac{f(x;\\theta)}{f(x;\\hat{\\theta})}\\right)f(x;\\theta) dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02cafaf-a7d5-4b37-b99d-6c7906fb7a46",
   "metadata": {},
   "source": [
    "That is the squared error loss, absolute error loss and the <a href=\"#\">Kullback-Leibler loss</a>.\n",
    "The term <a href=\"https://en.wikipedia.org/wiki/Loss_function\">loss function</a> will come up when\n",
    "we discuss machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61367744-98a3-4618-9734-47e2df1df300",
   "metadata": {},
   "source": [
    "----\n",
    "**Definition: Estimator risk**\n",
    "\n",
    "\n",
    "By definition the rist associated with an estimator $\\hat{\\theta}$ is given by\n",
    "\n",
    "$$R(\\theta, \\hat{\\theta})=E_{\\theta}\\left( L(\\theta, \\hat{\\theta})\\right)=\\int L(\\theta, \\hat{\\theta})f(x;\\theta)dx$$\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8ba96b-27c7-4ca3-b726-1e74847f2712",
   "metadata": {},
   "source": [
    "For example, consider the case where the loss function is the squared error. Then the rist is given by [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca96b3d-3bbd-4596-89d7-e84cd93c41ff",
   "metadata": {},
   "source": [
    "$$R(\\theta, \\hat{\\theta}) = Var_{\\theta}\\left(\\hat{\\theta}\\right) + B_{\\theta}^2\\left(\\hat{\\theta}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf2ba3-ed68-47da-8c69-25f4d97dcfe4",
   "metadata": {},
   "source": [
    "where $B$ is the bias term. In order to compare two estimators we can compare their risk functions. However, this does not provide always a clear answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b24c33-5120-4561-b4ed-8cdd5e1b6d7d",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b9f23-a9b1-4f8d-98f5-8153f13c0728",
   "metadata": {},
   "source": [
    "1. Larry Wasserman, _All of Statistics. A Concise Course in Statistical Inference_, Springer 2003."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
