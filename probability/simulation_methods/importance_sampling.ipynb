{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccab6955-c595-4a7e-bf3e-8bb62bffc36d",
   "metadata": {},
   "source": [
    "# Importance Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25544010-2991-408e-85a3-59b00ea9e22a",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9861ad67-a1fe-411c-8e5c-04e4f461c53f",
   "metadata": {},
   "source": [
    "Section [Basic Monte Carlo Integration](basic_monte_carlo_integration.ipynb) discussed \n",
    "Monte Carlo integration in its basic form. In this method we need to sample from a known distribution\n",
    "$f$. However, there may be cases where it is difficult to sample from it. \n",
    "\n",
    "In this section, we will introduce <a href=\"https://en.wikipedia.org/wiki/Importance_sampling\">importance sampling</a>.\n",
    "This is a generalization of the basic Monte Carlo method that overcomes the problem of sampling from a difficult distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cbaab3-135c-4723-9f21-6ac449f0c32e",
   "metadata": {},
   "source": [
    "## Importance sampling\n",
    "\n",
    "Let us consider once again the integral \n",
    "$$I=\\int_a^b h(x) dx$$\n",
    "\n",
    "and rewrite it as \n",
    "\n",
    "$$I=\\int_a^b \\omega(x)f(x)$$\n",
    "\n",
    "Importance sampling introduces a new probability distribution $g$, also known as the proposal distribution [2], \n",
    "that it is easier to  sample from. Thus we rewrite the integral as\n",
    "\n",
    "$$I=\\int_a^b \\frac{\\omega(x)f(x)}{g(x)}g(x)dx=E_g \\left[Y \\right]$$\n",
    "\n",
    "where $Y$ is the random variable defined by\n",
    "\n",
    "$$Y=\\frac{\\omega(x)f(x)}{g(x)}$$\n",
    "\n",
    "We can now sample from $g$ and estimate $I$ as\n",
    "\n",
    "$$\\hat{I}=\\frac{1}{N}\\sum_i Y_i$$\n",
    "\n",
    "Just like we did in the Monte Carlo integration section, we can use the law of \n",
    "large numbers and show that $\\hat{I}\\rightarrow I$ in probability.\n",
    "\n",
    "In importance sampling we draw samples from $g$ and re-weight the integral using importance weights so\n",
    "that the correct distribution is targeted [2]. However, $g$ in general has to have a similar shape with $f$. \n",
    "Moreover, it has to  have thicker  tails than $f$ otherwise the integral may become infinite [1]. \n",
    "Indeed, consider the second moment of $Y$:\n",
    "\n",
    "$$E_g\\left[ Y^2 \\right]=\\int Y^2g(x)dx=\\int \\frac{\\omega^2(x)f^2(x)}{g(x)}dx $$\n",
    "\n",
    "Thinner tails for $g$ means that it goes fatser to zero than what $f$ does. \n",
    "\n",
    "All in all, a good choice for $g$ is a distribution that is similar to $f$ but with thicker tails. In fact, the optimal choice for $g$ is given by the following theorem [1]\n",
    "\n",
    "----\n",
    "**Theorem**\n",
    "\n",
    "The choice of $g$ that minimizes the variance of $\\hat{I}$ is\n",
    "\n",
    "$$g(x)=\\frac{|h(x)|f(x)}{\\int |h(s)|f(s)ds}$$\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1b6a06-9332-4b99-b0dc-c4cafb0a8a66",
   "metadata": {},
   "source": [
    "## Python example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8292bdd-aeb1-43ab-9e21-d0e5723e8043",
   "metadata": {},
   "source": [
    "The first example we will consider is taken from [1]. We want to estimate the \n",
    "following probability; $P(Z > 3)$ where $Z\\sim N(0,1)$ This is just the integral:\n",
    "\n",
    "$$P(Z > 3) = \\int_{3}^{+\\infty}f(x)dx = \\int_{-\\infty}^{+\\infty}h(x)f(x)dx$$\n",
    "\n",
    "where $h(x)$ is 1 if $x > 3$ and 0 otherwise and $f(x)$ is the PDF for the standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946f3b6b-26de-4690-bf79-71a71d052eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import random\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d221d6b8-128c-4de0-a687-e0c3567ae2eb",
   "metadata": {},
   "source": [
    "Define $h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702c575e-5c59-4576-b21a-1ea5223e6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x)->float:\n",
    "    return 1 if x > 3.0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486f1ae-0ff2-4c4a-a187-9d45892fe4b7",
   "metadata": {},
   "source": [
    "Let $g\\sim N(4,1)$. We draw samples form $g$ and calculate  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666365f-8bc6-4bce-bc41-86fbd3d8667a",
   "metadata": {},
   "source": [
    "$$\\hat{I}=\\frac{1}{N}\\sum_i Y_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aae5ab5f-e74c-4893-badd-8a57804401ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E[I]=0.0013410013889053102\n",
      "V[I]=9.159774683823069e-08\n"
     ]
    }
   ],
   "source": [
    "# the sample size\n",
    "N = 100\n",
    "\n",
    "# how many iterations to perform\n",
    "n_iterations = 1000\n",
    "\n",
    "integrals = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    \n",
    "    integral = 0.0\n",
    "    \n",
    "    # sample the points from g\n",
    "    points = np.random.normal(4, 1, N)\n",
    "    for p in points:\n",
    "    \n",
    "        nominator = (h(p) * norm.pdf(p , loc=0.0 , scale=1.0))\n",
    "        denominator = norm.pdf(p, loc=4.0, scale=1.0)\n",
    "        value = nominator / denominator\n",
    "        integral += value\n",
    "        \n",
    "    integrals.append((integral) / float(N) )\n",
    "    \n",
    "print(f\"E[I]={np.mean(integrals)}\")\n",
    "print(f\"V[I]={np.var(integrals)}\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a189ac7e-6954-44bb-97bb-d36b75a551fd",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef08f83-3f22-4c7d-a90f-c5a9990da13b",
   "metadata": {},
   "source": [
    "In this section we reviewed importance sampling. This is another method that allows us to estimate integrals\n",
    "just like Monte Carlo integration. Importance sampling can be used when it is difficult\n",
    "to sample from $f$. \n",
    "\n",
    "Extensions of importance sampling, include sequential importance sampling, <a href=\"https://en.wikipedia.org/wiki/Particle_filter\">particle filtering</a> and <a href=\"https://en.wikipedia.org/wiki/Approximate_Bayesian_computation\">approximate Bayesian computation</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73da25f-b929-42b2-90e8-07e0adcdbfa7",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Larry Wasserman, _All of Statistics. A Concise Course in Statistical Inference_, Springer 2003.\n",
    "2. <a href=\"https://astrostatistics.psu.edu/su14/lectures/cisewski_is.pdf\">Imporatnce sampling</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
