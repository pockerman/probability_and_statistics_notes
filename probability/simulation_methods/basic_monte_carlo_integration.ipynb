{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be9d4e4-b546-4e50-bc75-3397c9bdb640",
   "metadata": {},
   "source": [
    "# Basic Monte Carlo Integration {#sec-basic-monte-carlo-integration}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c933c-58b3-4c34-b180-a3f37b7b094c",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4827ecf-718e-4591-ad28-57d22bab9852",
   "metadata": {},
   "source": [
    "In this section, we will look into <a href=\"https://en.wikipedia.org/wiki/Monte_Carlo_integration\">Monte Carlo integration</a>. Frequently in applications we need to evaluate integrals for which no analytical solution exists. Numerical methods can help us overcome this. Monte Carlo is just one of these methods. \n",
    "The method works due to the law of large numbers we saw in @sec-limit-theorems-clt. Compared to a standard numerical method, the method may not \n",
    "be especially efficient in one dimension, but it becomes increasingly efficient as the dimensionality of the integral grows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69911e31-2ac0-4d68-84c7-83873ba8ddad",
   "metadata": {},
   "source": [
    "## Monte Carlo integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be26a3-dbd3-466e-abec-03b3c446fd92",
   "metadata": {},
   "source": [
    "Let's assume that we want to evaluate the integral\n",
    "\n",
    "$$I=\\int_a^b h(x) dx$$\n",
    "\n",
    "If $f$ is a polynomial or a trigonometric function, then this integral can be calculated in closed form. \n",
    "However, in many cases there may not be  a closed for solution for $I$. Numerical techniques, such as <a href=\"https://en.wikipedia.org/wiki/Gaussian_quadrature\">Gaussian quadrature</a> or the the <a href=\"https://en.wikipedia.org/wiki/Trapezoidal_rule\">trapezoid rule</a> can  be \n",
    "employed in order to evaluate $I$. Monte Carlo integration is yet another techinque for evaluating complex integrals that is\n",
    "notable for its simplicity and generality [1].\n",
    "\n",
    "Let's begine by rewriting $I$ as follows\n",
    "\n",
    "$$I=\\int_a^b \\omega(x)f(x) dx$$\n",
    "\n",
    "where $\\omega=h(x)(b-a)$ and $f(x) = 1/(b-a)$ and $f$ is the probability density for a uniform random variable over $(a,b)$ [1]. \n",
    "Recall that the expectation for a continuous variable $X$ is given by\n",
    "\n",
    "$$E\\left[X\\right]=\\int xf(x)dx$$\n",
    "\n",
    "Hence, \n",
    "\n",
    "$$I=E\\left[\\omega(X)\\right]$$\n",
    "\n",
    "This is the basic Monte Carlo integration method [1]. In order to evaluate the integral $I$, we evaluate the following expression\n",
    "\n",
    "$$\\hat{I} = \\frac{1}{n}\\sum_{i=1}^{N}\\omega(x_i)$$\n",
    "\n",
    "where $x \\sim U(a,b)$. By the \n",
    "<a href=\"https://en.wikipedia.org/wiki/Law_of_large_numbers\">law of large numbers</a> it follows, [1],\n",
    "\n",
    "$$\\hat{I}\\rightarrow E\\left[\\omega(X)\\right] = I$$\n",
    "\n",
    "Notice that the law of large numbers, see @sec-limit-theorems-clt, provides us with probability convergence. Hence $\\hat{I}$ will converge in probability to $I$. The standard error, $\\hat{se}$, for the estimate is [1]\n",
    "\n",
    "$$\\hat{se} = \\frac{s}{\\sqrt{n}}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$s^2  = \\frac{\\sum_{i}^{N}(\\omega(x_i) - \\hat{I} )^2}{n - 1}$$\n",
    "\n",
    "A $1-\\alpha$ confidence interval for the estimate is given from, [1], \n",
    "\n",
    "$$\\hat{I} \\pm z_{\\alpha/2}\\hat{se}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05392cea-4314-4a87-9f1c-c2c1e398b151",
   "metadata": {},
   "source": [
    "## Python example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207dde51-afad-4682-b4fa-8941f76ff18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "520280f0-41a2-41a2-8a20-f498005091fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x*x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c654c2f6-a785-4a4c-b855-fe291117f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the random points\n",
    "N = [10, 100, 1000, 10000]\n",
    "a = 0.0\n",
    "b = 1.0\n",
    "exact_answer = 1.0 / 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f265933-c04c-4890-b37f-b8d759284585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size=10\n",
      "Calculated answer=0.4089009285012767\n",
      "Standard error of estimate 0.02962949840243374\n",
      "95% C.I. for estimate=[0.35082711163250657, 0.4669747453700468\n",
      "Sample size=100\n",
      "Calculated answer=0.2333997858544021\n",
      "Standard error of estimate 0.007428551162622636\n",
      "95% C.I. for estimate=[0.21883982557566173, 0.24795974613314248\n",
      "Sample size=1000\n",
      "Calculated answer=0.24887124843892253\n",
      "Standard error of estimate 0.002554323880305161\n",
      "95% C.I. for estimate=[0.2438647736335244, 0.2538777232443206\n",
      "Sample size=10000\n",
      "Calculated answer=0.2557902663480203\n",
      "Standard error of estimate 0.0008199960304503451\n",
      "95% C.I. for estimate=[0.2541830741283376, 0.257397458567703\n"
     ]
    }
   ],
   "source": [
    "for n in N:\n",
    "    print(f\"Sample size={n}\")\n",
    "    \n",
    "    # array of zeros of length N\n",
    "    random_points = np.zeros(n)\n",
    "    \n",
    "    integral = 0.0\n",
    "    y = []\n",
    "    for _ in range (n):\n",
    "        \n",
    "        point = random.uniform(a,b)\n",
    "        integral += f(point)\n",
    "        y.append(f(point)*(b-a))\n",
    "        \n",
    "    ans = (integral *(b-a)) / float(n) \n",
    "    print(f\"Calculated answer={ans}\")\n",
    "          \n",
    "    sum_2 = 0.0\n",
    "    for yi in y:\n",
    "          sum_2 += (yi - ans)*(yi - ans)\n",
    "    \n",
    "    s2 = np.sqrt(sum_2/(n-1))\n",
    "    se_hat = s2/np.sqrt(n)\n",
    "    print(f\"Standard error of estimate {se_hat}\")\n",
    "    print(f\"95% C.I. for estimate=[{ans - 1.96*se_hat}, {ans + 1.96*se_hat}\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cf0d3d-c844-4bf8-b72b-5139ca7d3c88",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53c69bf-84de-41e8-88ec-64fad050aac0",
   "metadata": {},
   "source": [
    "In this section we reviewed the Monte Carlo integration. This is a numerical integration method. \n",
    "In the basic form dicscussed herein, we sample points $x_i$ from the uniform distribution and evaluate the expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eb3d73-f9dc-4a89-854c-1a49c3a0d4c9",
   "metadata": {},
   "source": [
    "$$\\hat{I}=\\frac{1}{N}\\sum_{i=1}^{N} \\omega(x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d72fa5f-9acc-4f69-9e8e-d196b42c0f6b",
   "metadata": {},
   "source": [
    "According to the law of large numbers, $\\hat{I}$ will converge in probability to $I$. \n",
    "We also saw that a $1-\\alpha$ confidence interval is given by $$\\hat{I} \\pm z_{\\alpha/2}\\hat{se}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b5f39-7136-4658-b0c0-f3993529c15f",
   "metadata": {},
   "source": [
    " Standard Monte Carlo integration is great if we can sample from\n",
    "the target distribution (i.e. the desired distribution). However, this is not always possible.\n",
    "<a href=\"https://en.wikipedia.org/wiki/Importance_sampling\">Importance sampling</a> is a methodwe can use in order to \n",
    "overcome the proble of sampling from a difficult target distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc22ef-2c7f-466a-b980-101678485380",
   "metadata": {},
   "source": [
    "Finally, one advantage of this basic Monte Carlo integrator is that it is very easy to parallelize. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43c6a4-9685-4ef5-b806-aa6939dfd511",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Larry Wasserman, _All of Statistics. A Concise Course in Statistical Inference_, Springer 2003."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
