{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2912c5e-69a4-48c1-a9f5-5f07d6d41fa5",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1a63a1-51d9-434b-ae82-b02ebbbf46b0",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f7a68-44be-44d5-8e81-2dd3a3180d77",
   "metadata": {},
   "source": [
    "Many times when doing machnine learning we face the problem of having \n",
    "too many variables in the dataset in hand. Typically, not all the involved\n",
    "variables will contribute to the predictive power of a model. On the contrary,\n",
    "variables that do not contribute to the accuracy of the model should be removed as they\n",
    "increase the training time, the memory footprint and the model size. In addition,\n",
    "one of the best ways to understand a dataset is via viasualization. However,\n",
    "visualizing data in more than three dimensions is rather chellenging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8829cac7-1ddf-4b64-9dda-8eb06b80e6d2",
   "metadata": {},
   "source": [
    "In this section, we review one of the most used method for reducing\n",
    "the number of variables in a dataset namely; Principal Components Analysis or PCA for short.\n",
    "The list below shows the most commonly used dimensionality reduction techniques\n",
    "\n",
    "- Principal components analysis\n",
    "- Singular value decomposition\n",
    "- Linear discriminant analysis\n",
    "- Generalized discriminant analysis\n",
    "- Non-negative matrix factorization\n",
    "- Multi-dimension scaling\n",
    "- Locally linear embeddings\n",
    "- IsoMaps\n",
    "- Autoencoders\n",
    "- t-SNE (t-distributed stochastic neighbour embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5453bc-ea2d-4293-bc7c-50cafc475dfe",
   "metadata": {},
   "source": [
    "## Principal components analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1ebdeb-d9b8-42dd-9b7a-5bbd930fb076",
   "metadata": {},
   "source": [
    "Briefly, PCA projects the high-dimensional dataset to a lower dimensional one.\n",
    "In other words a dataset having $n$ number of variables is projected to a dataset\n",
    "with a $m$ number of variables where $m < n$. PCA transforms linearly the dataset; such methods \n",
    "are called feature projections. Thus, in PCA new variables are created that are linear combination\n",
    "of the variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535ce5b6-5275-485c-b92b-95a5e062c237",
   "metadata": {},
   "source": [
    "### PCA steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4cce7-e6a7-4229-8d83-e2f3cf26d8d4",
   "metadata": {},
   "source": [
    "Let's briefly describe the steps to be taken when performing PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473c978-50a4-437a-9915-60ee51f48f83",
   "metadata": {},
   "source": [
    "1. Normalize the dataset\n",
    "2. Compute the covariance matrix in the normalized dataset\n",
    "3. Compute the eigenvalues and the eigenvectors of the covariance matrix\n",
    "4. Sort eigenvalues in decreasing order\n",
    "5. Choose the eigenvectors that correspond to the top $k$ maximum eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f398c513-7294-4517-9242-9a20c8b4e304",
   "metadata": {},
   "source": [
    "## Computational example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d8ead91-3e1c-4bbf-8553-54fd6ea2bd3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb1bb37-8370-4086-8e3c-4a7bbf95c5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
