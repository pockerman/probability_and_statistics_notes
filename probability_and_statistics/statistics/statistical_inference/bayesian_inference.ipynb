{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e1e0b1-b127-4b6d-8d07-be1f7639eb96",
   "metadata": {},
   "source": [
    "# Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f376f5-151a-4878-99c3-6ac7f20fb26f",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396e4ba-c3cc-4bfa-8c14-c8efae50e13a",
   "metadata": {},
   "source": [
    "So far we have seen various methodologies for making inferences about population parameters; point estimation, \n",
    "hypothesis testing confidence intervals and  index of effect size. Each of these items communicates a different \n",
    "perspective regarding the findings of an investigation. The methodologies explored are based on the  frequentist approach of\n",
    "interpreting probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950572c6-90da-46e5-8104-42310e89fd3e",
   "metadata": {},
   "source": [
    "In this section, we intorduce the bayesian framwork for inference. The framework combines two elements; an assumed prior distribution\n",
    "of the unknown parameter $\\theta$ and the information contained in the observed data. By utilising <a href=\"https://en.wikipedia.org/wiki/Bayes'_theorem\">Bayes theorem</a>\n",
    "we obtain the posterior distribution of $\\theta$. This  is a conditional distribution of the unknown parameter, given the data [1].\n",
    "We can then use this distribution to perform inference on $\\theta$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b92988-2aa1-4bd3-ae94-f3dc9b2c5b78",
   "metadata": {},
   "source": [
    "## Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29dcd95-2ad3-4365-bd19-58d630a3e022",
   "metadata": {},
   "source": [
    "The Bayesian and the frequentist approach differ in how they treat uncertainty. In the frequentist approach all probabilities refer to random samples of data [1].\n",
    "Concepts such as confidence and significance levels as well as consistency also refer to long-run frequencies [1]. In the Bayesian approach uncertainty\n",
    "is also assigned to the unknown parameter $\\theta$. This assignement describes the fact that some values of $\\theta$ are more likely than others.\n",
    "More generally, this assignement implies a probability distribution of values for the unknown parameter. We call this distribution, the **prior distribution**.\n",
    "Overall, the prior distribution reflects our belief and past experiences about $\\theta$ before collecting any new data [1]. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d1a87-8936-4bdf-a679-e2671412cae0",
   "metadata": {},
   "source": [
    "The new collected data may enforce changing the nature of the prior distribution; i.e. the probabilities about $theta$ are governed by\n",
    "a new probability distribution. We call this the **posterior distribution** of $\\theta$ [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6e4be-6d8d-43d9-9575-569a2eab5f28",
   "metadata": {},
   "source": [
    "Thus, the prior distribution describes how $\\theta$ is governed, or our belief of that, before seeing the new data whereas the posterior distribution describes\n",
    "how $\\theta$ is governed after we see the new data. The two are connected via Bayes' theorem. Note that the above does not mean that prior and posterior distributions\n",
    "do not belong to the same family. In fact, when they do we call the prior distribution a conjugate to the posterior (more details further below). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14176f0-f9fe-4ca7-a5aa-07f1586b99ac",
   "metadata": {},
   "source": [
    "Before we move on, let's put together some of the notation we will be using. Thus within this section,\n",
    "we will denote the prior distribution for $\\theta$ using $\\pi(\\theta)$. Furthermore, we will denote the posterior distribution using $\\pi(\\theta | \\mathbf{X})$ where $\\mathbf{X}$ denotes \n",
    "the newly accummulated data. In addition, the observed data $\\mathbf{X}$ follow the distribution $f(\\mathbf{x}|\\theta)$. Notice that $f$ is conditioned on $\\theta$.\n",
    "Therefore, different values of the parameter, will generate a different distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41845e59-1d7a-4937-9c6a-0483321eadb0",
   "metadata": {},
   "source": [
    "We are now in a position to connect the prior and the posterior distributions. Recall Bayes' formula. Then "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a3fe8-7c39-4a49-b3d1-a5cd2f970a40",
   "metadata": {},
   "source": [
    "$$\\pi(\\theta | \\mathbf{X}) = \\frac{f(\\mathbf{x}|\\theta)\\pi(\\theta)}{q(\\mathbf{x})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bbb456-bf37-4d8a-aca9-2fe3858a3756",
   "metadata": {},
   "source": [
    "Where $q(\\mathbf{x})$ is the unconditional distribution of the data i.e. the marginal distribution of the sample $\\mathbf{X}$ [1]. It can be computed using the\n",
    "_Law of Total Probability_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7714087-1ae9-495f-8f68-5461a06c4e9a",
   "metadata": {},
   "source": [
    "### Conjugate distribution families"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb341c-18f0-4ae3-a4d5-26cd924cbbea",
   "metadata": {},
   "source": [
    "Given that the prior and the posterior are connect via $f$, it is natural to ask whether these can belong to the same family of distributions.\n",
    "This indeed can be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd77de0-06c1-48df-b741-036a1e4580a8",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "**Definition** \n",
    "\n",
    "A family of prior distributions $\\pi$ is conjugate to the model $f(\\mathbf{x}|\\theta)$ if the posterior distribution belongs to the same family [1]\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c8ba8d-994e-4d30-869a-028be1053fee",
   "metadata": {},
   "source": [
    "Let's see some classical examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df178c3c-fefe-462f-bc04-855d352ddff5",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e862951-3ad6-4788-b175-d70171d3dd40",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0bb2f-160c-434d-81dc-2a2c7a571117",
   "metadata": {},
   "source": [
    "1. Michael Baron, _Probability and statistics for computer scientists_, 2nd Edition, CRC Press."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2724a06f-b392-43ce-90b8-fef70f066ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
