{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the notes we use <a href=\"https://pytorch.org/\">PyTorch</a> in order to develop deep learning models. \n",
    "PyTorch is, at the time of writting, one of the most used frameworks for deep learing computations. Alongside its C++ implementation,\n",
    "it exposes  a Python API to simlify its use.  There are lots of resources to learn PyTorch. Hence, herein we just go over the basic elements of the library and how to use it. In particular, we will be focusing on the following core elements that deep learning algorithms use in order to train  a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```Module``` which contains ```Layers```\n",
    "- ```Optimizer```\n",
    "- ```Loss```\n",
    "- ```Trainer```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see each of these. We start with the ```Module```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Module```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, we build our networks around the ```nn.Module``` base class. For a simple case, we only have to define the structure of our network and implement the ```forward()``` function. This is shown below where we use the example in  <a href=\"https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e\">Understanding PyTorch with an example: a step-by-step tutorial</a> to set up a linear regression model in PyTorch.  Recall, that in linear regression we assume a model of the form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = ax + b + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically the model will establish its operation in the ```__init__``` method and apply them in the ```forward``` function that will compute the predicion(s) of the model. This is shown below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3f311cff30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # To make \"a\" and \"b\" real parameters of the model, we need to wrap them with nn.Parameter\n",
    "        self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Computes the outputs / predictions\n",
    "        return self.a + self.b * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Optimizer``` and ```Loss```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know by now, paramteric models, like deep neural networks, have to establish their parameters somehow.\n",
    "Optimization therefore is an essential component of PyTorch. This is built around the concept of\n",
    " the ```Optimizer``` and ```Loss```. When developing machine learning models we need a metric to measure the error or loss and an optimization method that works on that metric. We have seen this strategy in almost all the  previous lessons. The PyTorch ```optim``` module has a number of widedly used optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optimizer typically will have access to the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can define error metrics. PyTorch supports a number of error metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mean_squared_error_loss = nn.MSELoss()\n",
    "softmax_cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do linear regression, let's define an ```nn.MSELoss()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have everything we need right not to start training a model.  Let's generate some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x = np.random.rand(100, 1)\n",
    "y = 1 + 2 * x + .1 * np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffles the indices\n",
    "idx = np.arange(100)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Uses first 80 random indices for train\n",
    "train_idx = idx[:80]\n",
    "\n",
    "# Uses the remaining indices for validation\n",
    "val_idx = idx[80:]\n",
    "\n",
    "# Generates train and validation sets\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to PyTorch tensors\n",
    "x_train = torch.tensor(x_train)\n",
    "y_train = torch.tensor(y_train)\n",
    "x_val = torch.tensor(x_val)\n",
    "y_val = torch.tensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch> 0 loss 1.7223373385163594\n",
      "Epoch> 1 loss 1.714435262693462\n",
      "Epoch> 2 loss 1.7065720638565374\n",
      "Epoch> 3 loss 1.6987477402393498\n",
      "Epoch> 4 loss 1.6909620047670972\n",
      "Epoch> 5 loss 1.6832147139229239\n",
      "Epoch> 6 loss 1.6755056818239793\n",
      "Epoch> 7 loss 1.6678347659479926\n",
      "Epoch> 8 loss 1.6602016409484506\n",
      "Epoch> 9 loss 1.652606208820017\n",
      "OrderedDict([('a', tensor([0.6355])), ('b', tensor([0.3060]))])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    \n",
    "    model.train()\n",
    "    yhat = model(x_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # No more manual loss!\n",
    "    # error = y_tensor - yhat\n",
    "    # loss = (error ** 2).mean()\n",
    "    loss = mse_loss(y_train, yhat)\n",
    "    \n",
    "    print(\"Epoch> {0} loss {1}\".format(epoch, loss))\n",
    "\n",
    "    loss.backward()    \n",
    "    sgd_optimizer.step()\n",
    "    sgd_optimizer.zero_grad()\n",
    "\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a quick review of PyTorch have a look at the following links "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <a href=\"https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\">Deep Learning with PyTorch: A 60 Minute Blitz</a>\n",
    "- <a href=\"https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e\">Understanding PyTorch with an example: a step-by-step tutorial</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, <a href=\"https://www.fast.ai/\">fast.ai</a> has on online free of cost course geared around PyTorch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
