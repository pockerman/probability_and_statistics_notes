{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* [Acknowledgements](#ackw)\n",
    "* [Overview](#overview)\n",
    "* [PyTorch layers](#ekf)\n",
    "    * [Convolutional layers](#sub_sect_1)\n",
    "    * [Linear layers](#sub_sect_2) \n",
    "* [References](#refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ackw\"></a> Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is edited from the article <a href=\"https://towardsdatascience.com/pytorch-layer-dimensions-what-sizes-should-they-be-and-why-4265a41e01fd\">PyTorch layer dimensions: what size and why?</a> by Jake Krajewsky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"overview\"></a> Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ekf\"></a> PyTorch layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"sub_sect_1\"></a> Convolutional layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work first wit a ```Conv2d``` layer. The class constructor  expects the following: ```(n_samples, channels, height, width)```. Thus  the ```Conv2d``` layer requires a 4-dim ```tensor```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 1, kernel_size=(2, 2), stride=(2, 2))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "layer = nn.Conv2d(1, 1, 2, 2)\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2000, 1.2000],\n",
      "        [1.2000, 3.5000]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0.2, 1.2], [1.2, 3.5]])\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2000, 1.2000],\n",
      "         [1.2000, 3.5000]]])\n",
      "torch.Size([1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = x.unsqueeze(0)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2000, 1.2000],\n",
      "          [1.2000, 3.5000]]]])\n",
      "torch.Size([1, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = x.unsqueeze(1)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = x.unsqueeze(2)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to pass this data in a ```Conv2d``` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "out = layer(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"sub_sect_2\"></a> Linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PyTorch ```nn.Linear``` has the following constructor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "torch.nn.Linear(in_features: int, out_features: int, bias: bool = True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the layer expects the number of input features as well as the number of output features to be specified. Let's see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Linear(in_features=2, out_features=1)\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2000, 1.2000],\n",
      "        [1.2000, 3.5000]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0.2, 1.2], [1.2, 3.5]])\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "out = layer(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer weights: Parameter containing:\n",
      "tensor([[-0.3015,  0.2372]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear layer weights: {0}\".format(layer.weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way the ```nn.Linear``` interprets the input tensor ```x``` is as two batches of two-features vectors. What happens when we want to pass the data as one batch? We can use ```view()``` to get ```[batch_size, num_features]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2000, 1.2000, 1.2000, 3.5000]])\n",
      "torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "x = x.view(batch_size, -1)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"refs\"></a> References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
