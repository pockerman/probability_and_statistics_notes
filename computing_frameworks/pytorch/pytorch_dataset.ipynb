{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PyTorch ```Dataset``` {#sec-pytorch-dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"overview\"></a> Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [chapter @sec-pytorch-tensors] we discussed tensors; the building blocks for data in PyTorch. In this chapter, we want to go a step\n",
    "further and discuss how to represent a dataset in PyTorch. \n",
    "This is done using the abstract ```Dataset``` class.  As its name suggests, this class represents a dataset. \n",
    "Our custom dataset should inherit ```Dataset``` and override the  following two methods [1]:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```__len__``` i.e. ```len(dataset)``` should return the size of the data set\n",
    "- ```__getitem__``` to support the indexing such that ```dataset[i]``` can be used to get ith sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latter should return the item and its corresponding label.\n",
    "Before looking into how to create a custom dataset, we will discuss how to work with images, text and tabular data in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will be working with images and see how to handle these with PyTorch. The first thing you need\n",
    "to be aware of is that  PyTorch modules dealing with image data require tensors to be laid out as \n",
    "$C \\times H \\times W $ i.e. $(channels, height,  width)$. If this is not the case, we can use the\n",
    "```tensor.permute``` method to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PIL.Image as PILImage\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 1600, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_image = PILImage.open(Path(\"../../data/images/random/img1.jpeg\"))\n",
    "img = np.array(pil_image)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 598, 1600])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[3]:\n",
    "torch_img = torch.from_numpy(img)\n",
    "out = torch_img.permute(2, 0, 1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, we will feed our deep neural network with a batch of images. Let's see how can we create this. When storing images\n",
    "in a batch the first dimension describes the number of images in it i.e. $N \\times C \\times H \\times W $. There are two\n",
    "ways one can use to create a batch of images; the using the ```torch.stack``` function we have seen in the previous chapter or\n",
    "we can preallocate a tensor of appropriate size and fill it with images loaded from a directory. This is shown below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "channels = 3\n",
    "width = 256\n",
    "height = 256\n",
    "batch = torch.zeros(batch_size, channels, width, height, dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = Path('../../data/images/cracks')\n",
    "filenames = [name for name in os.listdir(data_dir)\n",
    "             if os.path.splitext(name)[-1] == '.jpg']\n",
    "\n",
    "counter = 0\n",
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = PILImage.open(os.path.join(data_dir, filename))\n",
    "    img_arr = np.array(img_arr)\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1)\n",
    "    \n",
    "    batch[i] = img_t\n",
    "    \n",
    "    counter +=1 \n",
    "    \n",
    "    if counter == batch_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our batch available, let's see how we can normalize the images. Normalization, is something that we typically want to\n",
    "perform when dealing with deep neural networks. We will do this per channel using the following\n",
    "\n",
    "$$\\text{normalized img channel} = \\frac{\\text{channel values} - \\text{channel mean}}{\\text{channel std}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# convert the batch into  a float\n",
    "batch = batch.float()\n",
    "#batch /= 255.0\n",
    "\n",
    "n_channels = batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c])\n",
    "    std = torch.std(batch[:, c])\n",
    "    batch[:, c] = (batch[:, c] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of writing, NLP or natural language processing, is a very popular subfield in the general domain of artificial intellience. \n",
    "Therefore in this section we will discuss how to import and process text based data with PyTorch. This is overall based on transforming\n",
    "text into numbers and feeding these in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "austine_jane_path = Path(\"../../data/text/austine_jane.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(austine_jane_path, encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use one-hot-encoding to represent text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for there was a distinctly feminine element in “Mr. Spectator,” and in'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lines = text.split('\\n')\n",
    "line = lines[200]\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "print(len(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s create a tensor that can hold the total number of one-hot-encoded characters for the whole line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[4]:\n",
    "letter_t = torch.zeros(len(line), 128)\n",
    "letter_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that letter_t holds a one-hot-encoded character per row. Now we just have to set a one on each row in the correct position so that each row represents the correct character. The index where the one has to be set corresponds to the index of the character in the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, letter in enumerate(line.lower().strip()):\n",
    "    letter_index = ord(letter) if ord(letter) < 128 else 0\n",
    "    letter_t[i][letter_index] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding whole words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one-hot encoded our sentence into a representation that a neural network could digest. \n",
    "Word-level encoding can be done the same way by establishing a vocabulary \n",
    "and one-hot encoding sentences—sequences of words—along the rows of our tensor. \n",
    "Since a vocabulary has many words, this will produce very wide encoded vectors, which may not be practical. We will see in the next section that there \n",
    "is a more efficient way to represent text at the word level, using embeddings. \n",
    "For now, let’s stick with one-hot encodings and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_words(in_str):\n",
    "    punctuation = '.,;:\"!?\"\"_-'\n",
    "    word_list = in_str.lower().replace('\\n',' ').split()\n",
    "    word_list = [word.strip(punctuation) for word in word_list]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('for there was a distinctly feminine element in “Mr. Spectator,” and in',\n",
       " ['for',\n",
       "  'there',\n",
       "  'was',\n",
       "  'a',\n",
       "  'distinctly',\n",
       "  'feminine',\n",
       "  'element',\n",
       "  'in',\n",
       "  '“mr',\n",
       "  'spectator,”',\n",
       "  'and',\n",
       "  'in'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_line = clean_words(line)\n",
    "line, words_in_line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch ```Dataset```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to handle various types of data with PyTorchDefine out own ```Dataset```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.array([[0.0, 1.0], \n",
    "              [2.0, 1.0], \n",
    "              [4.0, 5.5]])\n",
    "y = np.array([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExampleDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "        self._transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns the index-th training example and label\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if self._transform is not None:\n",
    "            x, y = elf._transform(self._X[index], self._y[index])\n",
    "        else:\n",
    "            \n",
    "            x = self._X[index] \n",
    "            y = self._y[index] \n",
    "        \n",
    "        return self._X[index], self._y[index] \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns how many items are in the dataset\n",
    "        \"\"\"\n",
    "        return self._X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples=3\n",
      "The first training example is=[0. 1.] with label=0\n"
     ]
    }
   ],
   "source": [
    "dataset = ExampleDataSet(X=X, y=y)\n",
    "print(\"Number of training examples={0}\".format(len(dataset)))\n",
    "print(\"The first training example is={0} with label={1}\".format(dataset[0][0], dataset[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch ```DataLoader```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ```DataLoader``` takes in a dataset and defines rules for successively generating batches of data. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "dataloader = DataLoader(dataset, batch_size=60, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"refs\"></a> References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href=\"https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\">Writing Custom Datasets, DataLoaders and Transforms</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
