{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb318e1e-ae2a-433c-91c9-203d8316be66",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7876afb-5431-4e8c-b542-bc8571c34698",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376a80c-fd0f-4b66-bb52-555bce9b877b",
   "metadata": {},
   "source": [
    "In this and the following two sections, we will discuss Spark SQL. This is the aspect of Spark\n",
    "that allows us to query a _DataFrame_ using SQL syntax. Spark SQL is indeed a core component of Spark as it allows\n",
    "to integrate relational like processing with the functional API exposed by Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6174417-9bf0-4782-96cb-f2f21521b275",
   "metadata": {},
   "source": [
    "## Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd33974-aeca-4b53-bc06-875e7b019e03",
   "metadata": {},
   "source": [
    "In this section,  we will introduce Spark SQL. This is a Spark interface that allows us to use SQL to query the data; see the script below.\n",
    "The script works with the Iris dataset but feel free to use any dataset you would like. We rename all the\n",
    "columns of the dataset so that an underscored is used instead of a dash. Otherwise Spark complains not being\n",
    "able to find colums\n",
    "\n",
    "```\n",
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "DATA_PATH = Path(\"/home/alex/qi3/qi3_notes/computational_mathematics/src/datasets/iris/iris.data\")\n",
    "APP_NAME = \"Spark SQL 1\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # get a spark session\n",
    "    spark = SparkSession.builder.appName(APP_NAME).getOrCreate()\n",
    "\n",
    "    schema = (\"`sepal-length` FLOAT, `sepal-width` FLOAT, \"\n",
    "              \"`petal-length` FLOAT, `petal-width` FLOAT, `class` STRING\")\n",
    "\n",
    "    # load the data\n",
    "    df = (spark.read.format(\"csv\")\n",
    "              .option(\"header\", False)\n",
    "              .option(\"inferSchema\", False)\n",
    "              .option(\"delimiter\", \",\")\n",
    "              .schema(schema)\n",
    "              .load(str(DATA_PATH)))\n",
    "\n",
    "    df.show(n=10)\n",
    "    df.printSchema()\n",
    "\n",
    "    # rename the columns\n",
    "    # we want to rename the column class to class-idx\n",
    "    new_df = (df.withColumnRenamed(\"sepal-length\", \"sepal_length\")\n",
    "              .withColumnRenamed(\"sepal-width\", \"sepal_width\")\n",
    "              .withColumnRenamed(\"petal-length\", \"petal_length\")\n",
    "              .withColumnRenamed(\"petal-width\", \"petal_width\"))\n",
    "\n",
    "    # create a temporary table\n",
    "    new_df.createOrReplaceTempView(\"iris_data_tbl\")\n",
    "\n",
    "    # now we can do SQL queries\n",
    "    query = \"\"\"SELECT sepal_length, sepal_width, class FROM iris_data_tbl WHERE \n",
    "    sepal_length > 2.3 AND sepal_width > 1.3 ORDER BY sepal_width DESC\"\"\"\n",
    "    spark.sql(query).show(n=10)\n",
    "\n",
    "    # use the CASE construct\n",
    "    query = \"\"\"SELECT sepal_length, petal_length, class, CASE WHEN sepal_length < 2.3 THEN 'SMALL' \n",
    "    WHEN sepal_length >= 2.3 AND sepal_length < 5.8 THEN 'MEDIUM' \n",
    "    WHEN sepal_length >= 5.8 THEN 'LARGE' \n",
    "    END AS Sepal_Length_Size FROM iris_data_tbl ORDER BY class DESC\"\"\"\n",
    "    spark.sql(query).show(n=20)\n",
    "    spark.stop()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2eaf24-cd4c-4036-8c95-2a8cab9ee642",
   "metadata": {},
   "source": [
    "The script introduces two new methods for us. Namely, ```spark.sql``` and ```df.createOrReplaceTempView```.\n",
    "The first is applied on a _SparkSession_ instance \n",
    "whilst the second one is applied on a _DataFrame_. Runnin the script produces the following\n",
    "\n",
    "```\n",
    "+------------+-----------+------------+-----------+-----------+\n",
    "|sepal-length|sepal-width|petal-length|petal-width|      class|\n",
    "+------------+-----------+------------+-----------+-----------+\n",
    "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
    "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
    "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
    "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
    "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
    "|         5.4|        3.9|         1.7|        0.4|Iris-setosa|\n",
    "|         4.6|        3.4|         1.4|        0.3|Iris-setosa|\n",
    "|         5.0|        3.4|         1.5|        0.2|Iris-setosa|\n",
    "|         4.4|        2.9|         1.4|        0.2|Iris-setosa|\n",
    "|         4.9|        3.1|         1.5|        0.1|Iris-setosa|\n",
    "+------------+-----------+------------+-----------+-----------+\n",
    "only showing top 10 rows\n",
    "\n",
    "root\n",
    " |-- sepal-length: float (nullable = true)\n",
    " |-- sepal-width: float (nullable = true)\n",
    " |-- petal-length: float (nullable = true)\n",
    " |-- petal-width: float (nullable = true)\n",
    " |-- class: string (nullable = true)\n",
    "\n",
    "+------------+-----------+-----------+\n",
    "|sepal_length|sepal_width|      class|\n",
    "+------------+-----------+-----------+\n",
    "|         5.7|        4.4|Iris-setosa|\n",
    "|         5.5|        4.2|Iris-setosa|\n",
    "|         5.2|        4.1|Iris-setosa|\n",
    "|         5.8|        4.0|Iris-setosa|\n",
    "|         5.4|        3.9|Iris-setosa|\n",
    "|         5.4|        3.9|Iris-setosa|\n",
    "|         5.7|        3.8|Iris-setosa|\n",
    "|         5.1|        3.8|Iris-setosa|\n",
    "|         5.1|        3.8|Iris-setosa|\n",
    "|         5.1|        3.8|Iris-setosa|\n",
    "+------------+-----------+-----------+\n",
    "only showing top 10 rows\n",
    "\n",
    "+------------+------------+--------------+-----------------+\n",
    "|sepal_length|petal_length|         class|Sepal_Length_Size|\n",
    "+------------+------------+--------------+-----------------+\n",
    "|         6.3|         6.0|Iris-virginica|            LARGE|\n",
    "|         6.9|         5.7|Iris-virginica|            LARGE|\n",
    "|         5.8|         5.1|Iris-virginica|            LARGE|\n",
    "|         7.1|         5.9|Iris-virginica|            LARGE|\n",
    "|         6.3|         5.6|Iris-virginica|            LARGE|\n",
    "|         6.5|         5.8|Iris-virginica|            LARGE|\n",
    "|         7.6|         6.6|Iris-virginica|            LARGE|\n",
    "|         4.9|         4.5|Iris-virginica|           MEDIUM|\n",
    "|         7.3|         6.3|Iris-virginica|            LARGE|\n",
    "|         6.7|         5.8|Iris-virginica|            LARGE|\n",
    "|         7.2|         6.1|Iris-virginica|            LARGE|\n",
    "|         6.5|         5.1|Iris-virginica|            LARGE|\n",
    "|         6.4|         5.3|Iris-virginica|            LARGE|\n",
    "|         6.8|         5.5|Iris-virginica|            LARGE|\n",
    "|         5.7|         5.0|Iris-virginica|           MEDIUM|\n",
    "|         5.8|         5.1|Iris-virginica|            LARGE|\n",
    "|         6.4|         5.3|Iris-virginica|            LARGE|\n",
    "|         6.5|         5.5|Iris-virginica|            LARGE|\n",
    "|         7.7|         6.7|Iris-virginica|            LARGE|\n",
    "|         7.7|         6.9|Iris-virginica|            LARGE|\n",
    "+------------+------------+--------------+-----------------+\n",
    "only showing top 20 rows\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43ab8ea-abf5-4cf1-ae18-f4049777dbe9",
   "metadata": {},
   "source": [
    "### Create a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220cab7-3fb5-47fc-b7df-b8e6db449f67",
   "metadata": {},
   "source": [
    "\n",
    "Tables will reside in a database. In addition, Spark supports two types of tables; managed and unmanaged.\n",
    "A managed table means that Soark handles both the data and the metadata. For an unmanged table, Spark only manages\n",
    "the metadata. The following script, show how to create a database in Spark.\n",
    "\n",
    "\n",
    "```\n",
    "spark.sql(\"CREATE DATABASE iris_db\")\n",
    "spark.sql(\"Use iris_db\")\n",
    "```\n",
    "\n",
    "Just like in SQL, we need to instruct Spark about the database we want to use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee48117-b1fc-41a0-94f8-0e9061adf109",
   "metadata": {},
   "source": [
    "### Create managed table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb5173-c4a7-432d-92a8-c00ae8f52b7f",
   "metadata": {},
   "source": [
    "There are two ways to create a managed table;\n",
    "\n",
    "- Use SQL\n",
    "- Wrie a _DataFrame_ as a table\n",
    "\n",
    "The first approach is illustrated in the script below\n",
    "\n",
    "```\n",
    "query =\"CREATE TABLE managed_iris_data (sepal_length FLOAT, sepal_width FLOAT, petal_length FLOAT, petal_width FLOAT, class STRING)\"\n",
    "spark.sql(query)\n",
    "```\n",
    "\n",
    "This is very similar, if not exactly the same as we do in SQL. Howver, if you have _DataFrame_ you can persist in a table as\n",
    "simple as issuing\n",
    "\n",
    "```\n",
    "df.write.saveAsTable(\"managed_iris_data\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43c868-94a8-4683-b283-3bc741689d83",
   "metadata": {},
   "source": [
    "### Create unmanaged table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3697d309-8f74-415c-a227-56d1dc1c24b1",
   "metadata": {},
   "source": [
    "We can create an unmanaged table from data sources e.g. Parquet and CSV files as follows.\n",
    "\n",
    "```\n",
    "query =\"CREATE TABLE iris_data (sepal_length FLOAT, sepal_width FLOAT, petal_length FLOAT, petal_width FLOAT, class STRING)\n",
    "USING csv OPTIONS (PATH '/your/path/to/your/csv_data'\"\n",
    "spark.sql(query)\n",
    "```\n",
    "\n",
    "And similarly using _DataFrame_\n",
    "\n",
    "```\n",
    "df.write.options(\"path\", \"/your/path/to/your/csv_data\").saveAsTable(\"iris_data\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7086b93-8859-47b6-a617-f4601277208e",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09446c92-6669-4adc-a6b9-b61c51c38280",
   "metadata": {},
   "source": [
    "This section touched upon the Spark SQL API using a simple example. The Spark SQL API allows us to use SQL in order to query\n",
    "a _DataFrame_. This is done by first creating either  a table or a view. \n",
    "Tables in Spark can be managed or unmanged.\n",
    "The next section discusses Spark Views."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6999fe01-ec60-426c-a529-3087ecf74b4a",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ff37f-139d-411c-bc5b-ce6960dc30ab",
   "metadata": {},
   "source": [
    "1. Jules S. Damji, Brooke Wenig, Tathagata Das, Deny Lee, _Learning Spark. Lighting-fasts data analytics_, 2nd Edition, O'Reilly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
