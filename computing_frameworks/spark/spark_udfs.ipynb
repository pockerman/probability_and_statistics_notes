{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99fb103-d6e3-4afd-96e9-886f88a4d5ad",
   "metadata": {},
   "source": [
    "# Spark User Defined Functions\n",
    "\n",
    "## Overview\n",
    "\n",
    "Spark provides a powerful computational engine and we have seen some core aspects of it thus far. In this\n",
    "section, we will look into how to create user defined functions and integrate these in Spark.\n",
    "\n",
    "## User defined functions in Spark\n",
    "\n",
    "UDFs are custom per-row transformations\n",
    "in native Python that run in parallel on your data. The obvious question is, why not only use UDFs?\n",
    "After all, they are also more flexible. There is a hierarchy of tools you should look to use for speed\n",
    "reasons. Speed is a significant consideration and should not be ignored. Ideally, you should get the most\n",
    "bang for your buck using Python DataFrame APIs and their native functions/methods. DataFrames\n",
    "go through many optimizations, so they are ideally suited for semi-structured and structured data.\n",
    "The methods and functions Spark provides are also heavily optimized and designed for the most\n",
    "common data processing tasks. Suppose you find a case where you just can’t do what is required with\n",
    "the native functions and methods and you are forced to write UDFs. UDFs are slower because Spark\n",
    "can’t optimize them. They take your native language code and serialize it into the JVM, then pass it\n",
    "across the cluster. I have come across many cases where objects can’t be serialized, which can be a\n",
    "pain to deal with. Also, this whole process is much slower for non-JVM languages. I always like to\n",
    "caution against UDFs unless no other choice is possible.\n",
    "\n",
    "The code snippet below shows you how to define a simple UDF in Spark.\n",
    "It accepts a string column and returns a modified version of that string\n",
    "\n",
    "```python\n",
    "\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "\n",
    "def add_string(string):\n",
    "    return string + \"_\" + \"this_is_added\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: filename <file>\", file=sys.stderr)\n",
    "\n",
    "    # get a spark session\n",
    "    spark = SparkSession.builder.appName(APP_NAME).getOrCreate()\n",
    "\n",
    "    # read the filename from the commandline\n",
    "    rows = [Row(180.0, 85.0, 35, \"M\"),\n",
    "            Row(175.5, 75.5, 25, \"M\"),\n",
    "            Row(165.3, 55.3, 19, \"F\")]\n",
    "\n",
    "    # create the DataFrame\n",
    "    df = spark.createDataFrame(rows, [\"Height\", \"Weight\", \"Age\", \"Sex\"])\n",
    "    df.show()\n",
    "\n",
    "    # use expr function\n",
    "    df.select(expr(\"Height * 5\")).show()\n",
    "\n",
    "    #...or use column\n",
    "    df.select(\"Height\", col(\"Height\") * 5, \"Weight\", col(\"Weight\") * 2, \"Age\", \"Sex\").show()\n",
    "\n",
    "    # before using the UDF we need to register it\n",
    "    addStringUDF = udf(lambda i: add_string(i),StringType())\n",
    "\n",
    "    spark.stop()\n",
    "    \n",
    "```\n",
    "\n",
    "If we want to use our UDF in native SQL statements, then we also need to register it as shown below:\n",
    "\n",
    "```python\n",
    "spark.udf.register(\"addStringUDF\", addString,StringType())\n",
    "\n",
    "```\n",
    "\n",
    "## Summary\n",
    "\n",
    "## References\n",
    "\n",
    "1. Jules S. Damji, Brooke Wenig, Tathagata Das, Deny Lee, _Learning Spark. Lighting-fasts data analytics_, 2nd Edition, O'Reilly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
