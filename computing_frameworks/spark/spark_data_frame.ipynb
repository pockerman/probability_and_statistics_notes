{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162f36fe-3c7a-4f1a-96ad-66023a116d12",
   "metadata": {},
   "source": [
    "# Spark DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52bc10-cc78-4fde-b12e-85ded2388e65",
   "metadata": {},
   "source": [
    "## Oberview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa2dd24-7c66-4332-be79-c27fc80a40ee",
   "metadata": {},
   "source": [
    "The previous section showed you how to read a CSV file into Spark. The result is stored in a data structured called\n",
    "DataFrame. A Spark DataFrame is a like a distributed in-memory table [1]. As a table like structure it has\n",
    "columns and each column has a specific data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af3a19-8a9e-4c49-9baf-bd7106ed419e",
   "metadata": {},
   "source": [
    "DataFrames play a key role in developing Spark applications. In this section we will go over the core elements you need\n",
    "to know in order to work efficiently with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6708a4-eb01-4c5d-acba-d773b249b669",
   "metadata": {},
   "source": [
    "## Spark DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d18dc40-5d4d-4759-b491-90455e1034a2",
   "metadata": {},
   "source": [
    "A Spark DataFrame is a like a distributed in-memory table [1]. As a table like structure it has\n",
    "columns and each column has a specific data type. DataFrames are immutable and this allows Spark to keep a lineage of all the\n",
    "transformations applied on them. A DataFrame has a certain schema [1]. A schema defines the column names and the associated data types.\n",
    "When reading data from a specific source we can either let Spark infer the schema, just like we did in the previous section, or explicitly\n",
    "specifying the schema. The latter approach has two distinct benefits [1]:\n",
    "\n",
    "- Inferring data can be tricky and hence time consuming; Spark needs to creat a separate job, read a large portion of the data and then infer the schema\n",
    "- Providing the schema means we can infer quickly if the data doesn't match the proposed schema.\n",
    "\n",
    "Let's see belwo how an application can provide the schema of a dataset in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0722032-726f-495f-8168-dab334b41e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "349908d8-4ab9-42ab-8f81-b396bc02198f",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c4f76b-0fe3-4d63-b4a1-896066f0fd28",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a4a766-3410-4f3d-95c3-a8e58cab3e2d",
   "metadata": {},
   "source": [
    "1. Jules S. Damji, Brooke Wenig, Tathagata Das, Deny Lee, _Learning Spark. Lighting-fasts data analytics_, 2nd Edition, O'Reilly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
